This repo contains the dataset and related materials associated with the paper: 

*Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability To Mark Short Answer Questions in K-12 Education*

This dataset is available for use for non-commercial uses only, with attribution (CC-BY-NC 4.0)

Final Paper : https://dl.acm.org/doi/10.1145/3657604.3664693

Pre-Print: https://arxiv.org/abs/2405.02985

To Cite

Owen Henkel, Libby Hills, Adam Boxer, Bill Roberts, and Zach Levonian. 2024. Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability To Mark Short Answer Questions in K-12 Education. In Proceedings of the Eleventh ACM Conference on Learning @ Scale (L@S '24). Association for Computing Machinery, New York, NY, USA, 300â€“304. https://doi.org/10.1145/3657604.3664693
